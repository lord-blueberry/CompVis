{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FCNs for semantic segmentation\n",
    "\n",
    "In this exercise we will look at the basics how to build a fully convolutional network for semantic segmentation.\n",
    "\n",
    "## A first example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install all needed packages\n",
    "from typing import Tuple\n",
    "import numpy as np\n",
    "import skimage\n",
    "import skimage.data\n",
    "import skimage.io\n",
    "import tensorflow.keras as keras\n",
    "\n",
    "\n",
    "# for displaying images in jupyter\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.figsize'] = [10, 10]\n",
    "#mpl.rcParams['figure.dpi']= 400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check tensorflow installation to see if we have GPU support\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Images for smoke tests\n",
    "\n",
    "When building a new network, it is a good idea to check if the network works at all, as it can sometimes take a while until all the parameters are fixed. For that we generate some function to create some simple test images that we can use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_random_binary_test_image(height: int, width: int)->(np.ndarray, np.ndarray):\n",
    "    \"\"\"\n",
    "    Generate a test image and an appropriate label image with label 0 or label 1\n",
    "    Label 0 images have a lower medium grayscale value, label 1 images a higher one.\n",
    "    \n",
    "    The returned images will have shape (height, width, 1) and type uint8 to be as compatible as possible to \n",
    "    mages read from files\n",
    "    \"\"\"\n",
    "    VALUE = [100.0, 200.0]\n",
    "    CLASS_ID = [0, 1]\n",
    "    NOISE = 20.0\n",
    "    \n",
    "    label = np.zeros((height, width, 1), dtype=np.uint8)\n",
    "    class_id = np.random.choice(CLASS_ID)\n",
    "    label.fill(class_id)\n",
    "    img = np.random.normal(VALUE[class_id], NOISE, ((height, width, 1))).astype(np.uint8)\n",
    "    \n",
    "    return img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image, label = gen_random_binary_test_image(128, 128)\n",
    "print('mean: {}'.format(np.mean(image)))\n",
    "print('mask: {}'.format(np.max(label)))\n",
    "plt.imshow(image.reshape((image.shape[0], image.shape[1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batch of data\n",
    "\n",
    "Training is usually done using a batch of data. For semantic segmentation, that will be a batch of image (patches). We will also add the normalization of the data in this step. \n",
    "\n",
    "We will just scale the images in the range 0.0 to 1.0 from the full range of 0 to 255. Other possibilities are to scale the images individually according to their minimum and maximum values.\n",
    "\n",
    "We will also convert the label images to a 1d Array to match the output of the network (we will see about that in the next step).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_batch_binary(batch_size, height: int, width: int):\n",
    "    image_list = []\n",
    "    label_list = []\n",
    "    for i in range(batch_size):\n",
    "        img, label = gen_random_binary_test_image(height=height, width=width)\n",
    "        image_list.append(img.astype(np.float32) / 255.0)\n",
    "        label_list.append(label.astype(np.float32))\n",
    "\n",
    "    image_batch = np.array(image_list, dtype=np.float32)\n",
    "    label_batch = np.array(label_list, dtype=np.float32)\n",
    "\n",
    "    # reshape labels as this is not done in the model\n",
    "    label_batch = label_batch.reshape(batch_size, height*width, 1)\n",
    "\n",
    "    return image_batch, label_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_batch, label_batch = gen_batch_binary(100, 128, 128)\n",
    "print(image_batch.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple FCN\n",
    "\n",
    "We will create a simple fully convolutional neural network for processing a batch of image patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fcn_simple_no_border(input_height:int, input_width:int) -> keras.Model:\n",
    "    \"\"\"\n",
    "    Create a simple fcn model for semantic segmentation with 2 classes\n",
    "    \"\"\"\n",
    "    model = keras.Sequential()\n",
    "    \n",
    "    # we use grayscale (1-channel input)\n",
    "    \n",
    "    # (used to define input shape on the first layers)\n",
    "    model.add(keras.layers.Layer(input_shape=(input_height , input_width, 1)))\n",
    "    \n",
    "    # add 3 convolutional layers with 3x3 filters\n",
    "    model.add(keras.layers.Convolution2D(filters=4, kernel_size=3, padding='same', activation='relu'))\n",
    "    model.add(keras.layers.Convolution2D(filters=8, kernel_size=3, padding='same', activation='relu'))\n",
    "    model.add(keras.layers.Convolution2D(filters=4, kernel_size=3, padding='same', activation='relu'))\n",
    "    \n",
    "    # go to logits which is the number of classes and add sigmoid layer for activation\n",
    "    model.add(keras.layers.Convolution2D(filters=1, kernel_size=1, activation=None, \n",
    "                                         kernel_initializer=keras.initializers.TruncatedNormal(mean=0.0, stddev=0.001, seed=None)))\n",
    "    model.add(keras.layers.Activation('sigmoid'))\n",
    "    \n",
    "    # reshape so that we have a sample for each pixel\n",
    "    model.add(keras.layers.Reshape(target_shape=(input_height * input_width, 1)))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = fcn_simple_no_border(128, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets see if the model works...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(image_batch, label_batch, epochs=20, batch_size = 10, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training accuracy values\n",
    "plt.plot(history.history['acc'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.plot(history.history['loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('min, max, mean: {},{}, {}'.format(np.min(image_batch), np.max(image_batch), np.mean(image_batch)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training with generators\n",
    "\n",
    "Reading the whole data set into memory is not always possible. There are different possibilities to that problem, one is to use the Dataset classes in the tensorflow backend. We will look at that a bit more in the next lecture. The other possibility is to use *generators* from python. A generator function to use for keras will generate a batch of data at the time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_generator(batch_size, height: int, width: int):\n",
    "    while True:\n",
    "        image_batch, label_batch = gen_batch_binary(batch_size=batch_size, height=height, width=width)\n",
    "        yield image_batch, label_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to use the generator, we use the ```model.fit_generator``` function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATCH_HEIGHT = 128\n",
    "PATCH_WIDTH = 128\n",
    "BATCH_SIZE = 50\n",
    "EPOCHS = 10\n",
    "STEPS_PER_EPOCHS = 10\n",
    "model = fcn_simple_no_border(PATCH_HEIGHT, PATCH_WIDTH)\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "history = model.fit_generator(\n",
    "        generator=batch_generator(BATCH_SIZE, PATCH_HEIGHT, PATCH_WIDTH),\n",
    "        epochs=EPOCHS,\n",
    "        verbose=1,\n",
    "        steps_per_epoch=STEPS_PER_EPOCHS,\n",
    "        shuffle=False,\n",
    "        callbacks=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1: Categorical data\n",
    "\n",
    "In the example above we had only two classes, but in most applications we want to classify into more classes, as you have for example already done in the first homework, when classifying number.\n",
    "\n",
    "Change the network and the generation of examples to use 5 classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see solution below that uses both padding and categorical data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2: Padding\n",
    "\n",
    "Also in the example, we used padding for the convolutional filters by specifying ```padding='same'```. However this will not process the data at the edges correctly as the missing data will be filled with 0. For training it is preferable to use only the data that fits inside the convolutional filters. This can be specified using ```padding='valid'```. However then the labels will have to be resized accordingly.\n",
    "\n",
    "Change the network to use *valid* padding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fcn_simple_border(input_height:int, input_width:int, nr_classes:int) -> (keras.Model, int):\n",
    "    \"\"\"\n",
    "    Create a simple fcn model for semantic segmentation with 2 classes.\n",
    "    Return both the model and the border size\n",
    "    \"\"\"\n",
    "    model = keras.Sequential()\n",
    "    border = 0;\n",
    "    \n",
    "    # we use grayscale (1-channel input)\n",
    "    \n",
    "    # (used to define input shape on the first layers)\n",
    "    model.add(keras.layers.Layer(input_shape=(input_height , input_width, 1)))\n",
    "    \n",
    "    # add 3 convolutional layers with 3x3 filters\n",
    "    model.add(keras.layers.Convolution2D(filters=4, kernel_size=3, padding='valid', activation='relu'))\n",
    "    border = border + 1\n",
    "    model.add(keras.layers.Convolution2D(filters=8, kernel_size=3, padding='valid', activation='relu'))\n",
    "    border = border + 1\n",
    "    model.add(keras.layers.Convolution2D(filters=4, kernel_size=3, padding='valid', activation='relu'))\n",
    "    border = border + 1\n",
    "    \n",
    "    # go to logits which is the number of classes and add sigmoid layer for activation\n",
    "    model.add(keras.layers.Convolution2D(filters=nr_classes, kernel_size=1, activation=None, \n",
    "                                         kernel_initializer=keras.initializers.TruncatedNormal(mean=0.0, stddev=0.001, seed=None)))\n",
    "    model.add(keras.layers.Activation('softmax'))\n",
    "    \n",
    "    # reshape so that we have a sample for each pixel\n",
    "    model.add(keras.layers.Reshape(target_shape=((input_height-2*border) * (input_width-2*border), nr_classes)))\n",
    "    \n",
    "    return model, border\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, border = fcn_simple_border(128, 128, 5)\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_random_binary_test_image_classes(height: int, width: int, nr_classes)->(np.ndarray, np.ndarray):\n",
    "    \"\"\"\n",
    "    Generate a test image and an appropriate label image with label 0 or label 1\n",
    "    Label 0 images have a lower medium grayscale value, label 1 images a higher one.\n",
    "    \n",
    "    The returned images will have shape (height, width, 1) and type uint8 to be as compatible as possible to \n",
    "    mages read from files\n",
    "    \"\"\"\n",
    "    class_id = np.random.choice(range(nr_classes))\n",
    "    value = 255.0 * class_id / nr_classes \n",
    "    \n",
    "    NOISE = 20.0\n",
    "    \n",
    "    label = np.zeros((height, width, 1), dtype=np.uint8)\n",
    "    label.fill(class_id)\n",
    "    img = np.random.normal(value, NOISE, ((height, width, 1))).astype(np.uint8)\n",
    "    \n",
    "    return img, label\n",
    "\n",
    "def gen_batch_binary_with_border(batch_size, height: int, width: int, border: int, nr_classes:int):\n",
    "    image_list = []\n",
    "    label_list = []\n",
    "    for i in range(batch_size):\n",
    "        img, label = gen_random_binary_test_image_classes(height=height, width=width, nr_classes=nr_classes)\n",
    "        label = label[border:-border, border:-border]\n",
    "        image_list.append(img.astype(np.float32) / 255.0)\n",
    "        label_list.append(label.astype(np.float32))\n",
    "\n",
    "    image_batch = np.array(image_list, dtype=np.float32)\n",
    "    label_batch = np.array(label_list, dtype=np.float32)\n",
    "\n",
    "    # reshape labels as this is not done in the model\n",
    "    label_batch = label_batch.reshape(batch_size, (height-2*border)*(width-2*border), 1)\n",
    "    label_batch = keras.utils.to_categorical(label_batch, num_classes=nr_classes)\n",
    "\n",
    "    return image_batch, label_batch\n",
    "\n",
    "def batch_generator_with_border(batch_size, height: int, width: int, border: int, nr_classes:int):\n",
    "    while True:\n",
    "        image_batch, label_batch = gen_batch_binary_with_border(batch_size=batch_size, \n",
    "                                                                height=height, width=width, \n",
    "                                                                border=border, nr_classes=nr_classes)\n",
    "        yield image_batch, label_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATCH_HEIGHT = 128\n",
    "PATCH_WIDTH = 128\n",
    "BATCH_SIZE = 50\n",
    "EPOCHS = 20\n",
    "STEPS_PER_EPOCHS = 20\n",
    "NR_CLASSES = 5\n",
    "model, border = fcn_simple_border(PATCH_HEIGHT, PATCH_WIDTH, NR_CLASSES)\n",
    "model.compile(optimizer='adagrad', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "history = model.fit_generator(\n",
    "        generator=batch_generator_with_border(BATCH_SIZE, PATCH_HEIGHT, PATCH_WIDTH, border, NR_CLASSES),\n",
    "        epochs=EPOCHS,\n",
    "        verbose=1,\n",
    "        steps_per_epoch=STEPS_PER_EPOCHS,\n",
    "        shuffle=False,\n",
    "        callbacks=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training accuracy values\n",
    "plt.plot(history.history['acc'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Plot training loss values\n",
    "plt.plot(history.history['loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3: Data preparation for homework 2\n",
    "\n",
    "In the homework, you should train a network to recognise different texture categories from the describable texture data base. If you have already downloaded the data and/or extracted it, copy it to the current folder for this exercise (otherwise it will download again). The following function will download and prepare the dataset by converting it to grayscale, extract a smaller region in the center and renaming the files consecutively. It will also divide the data into 3 sets for training, validation and testing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dtd_loader import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_and_convert()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
